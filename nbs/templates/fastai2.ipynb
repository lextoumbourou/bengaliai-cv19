{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import wandb\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.callback.wandb import *\n",
    "from fastai2.vision.all import *\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sys.path.append('/home/lextoumbourou/bengaliai-cv19')\n",
    "\n",
    "from bengali.model import MishHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "NAME = ''\n",
    "WANDB_MODE = 'dryrun'\n",
    "\n",
    "DATA_PATH = Path('/home/lextoumbourou/bengaliai-cv19/data')\n",
    "IMAGE_DATA_PATH = Path(DATA_PATH/'grapheme-imgs-128x128')\n",
    "OUTPUT_PATH = Path(DATA_PATH/'working')\n",
    "LABELS_PATH  = Path(DATA_PATH/'iterative-stratification')\n",
    "\n",
    "VALID_PCT = 0.2\n",
    "SEED = 420\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 64\n",
    "\n",
    "MAX_WARP = 0.2\n",
    "P_AFFINE = 0.75\n",
    "MAX_ROTATE = 10.\n",
    "MAX_ZOOM = 1.1\n",
    "P_LIGHTING = 0.75\n",
    "MAX_LIGHTING = 0.2\n",
    "MAX_COUNT_RANDOM_ERASING = 3\n",
    "\n",
    "ENCODER_ARCH = 'efficientnet-b0'\n",
    "\n",
    "GRAPHEME_ROOT_WEIGHT = 2\n",
    "VOWEL_DIACRITIC_WEIGHT = 1\n",
    "CONSONANT_DIACRITIC_WEIGHT = 1\n",
    "MODEL_HEAD = 'mish_head'\n",
    "\n",
    "SAMPLE_SIZE = None\n",
    "if not torch.cuda.is_available():\n",
    "    SAMPLE_SIZE = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login 563765550fd7b64fd10129216209724e03f3f20c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this off before running!!\n",
    "os.environ['WANDB_MODE'] = WANDB_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"bengaliai-cv19\", name=NAME)\n",
    "\n",
    "wandb.config.img_size = IMG_SIZE\n",
    "wandb.config.batch_size = BATCH_SIZE\n",
    "wandb.config.seed = SEED\n",
    "\n",
    "wandb.config.max_warp = MAX_WARP\n",
    "wandb.config.p_affine = P_AFFINE\n",
    "wandb.config.max_rotate = MAX_ROTATE\n",
    "wandb.config.max_zoom = MAX_ZOOM\n",
    "wandb.config.p_lighting = P_LIGHTING\n",
    "wandb.config.max_lighting = MAX_LIGHTING\n",
    "wandb.config.max_count_random_erasing = MAX_COUNT_RANDOM_ERASING\n",
    "wandb.config.grapheme_root_weight = GRAPHEME_ROOT_WEIGHT\n",
    "wandb.config.vowel_diacritic_weight = VOWEL_DIACRITIC_WEIGHT\n",
    "wandb.config.consonant_diacritic_weight = CONSONANT_DIACRITIC_WEIGHT\n",
    "wandb.config.sample_size = SAMPLE_SIZE\n",
    "wandb.config.ENCODER_ARCH = ENCODER_ARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_kwargs = dict(size=wandb.config.img_size, mode='bilinear', pad_mode=PadMode.Reflection, batch=False)\n",
    "\n",
    "AUGMENTATIONS = [\n",
    "    Warp(magnitude=wandb.config.max_warp, p=wandb.config.p_affine, **aug_kwargs),\n",
    "    Rotate(max_deg=wandb.config.max_rotate, p=wandb.config.p_affine, **aug_kwargs),\n",
    "    Zoom(max_zoom=wandb.config.max_zoom, p=wandb.config.p_affine, **aug_kwargs),\n",
    "    Brightness(max_lighting=wandb.config.max_lighting, p=wandb.config.p_lighting, batch=False),\n",
    "    Contrast(max_lighting=wandb.config.max_lighting, p=wandb.config.p_lighting, batch=False),\n",
    "    RandomErasing(max_count=wandb.config.max_count_random_erasing)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(LABELS_PATH/'train_with_fold.csv')\n",
    "if wandb.config.sample_size:\n",
    "    print(\"About to reduce train size.\")\n",
    "    train_df = train_df.sample(n=wandb.config.sample_size, random_state=SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock(cls=PILImageBW), CategoryBlock, CategoryBlock, CategoryBlock),\n",
    "    getters=[\n",
    "        ColReader('image_id', pref=IMAGE_DATA_PATH, suff='.png'),\n",
    "        ColReader('grapheme_root'),\n",
    "        ColReader('vowel_diacritic'),\n",
    "        ColReader('consonant_diacritic')\n",
    "    ],\n",
    "    splitter=IndexSplitter(train_df.loc[train_df.fold==0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = AUGMENTATIONS + [Normalize(mean=0.485, std=0.229)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datablock.dataloaders(train_df, bs=wandb.config.batch_size, batch_tfms=tfms)\n",
    "data.n_inp = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(inp, grapheme_root_targ, vowel_diacritic_targ, consonant_diacritic_targ, *args, **kwargs):\n",
    "    grapheme_root_inp, vowel_diacritic_inp, consonant_diacritic_inp = inp\n",
    "\n",
    "    return (\n",
    "        F.cross_entropy(grapheme_root_inp, grapheme_root_targ) * wandb.config.grapheme_root_weight +\n",
    "        F.cross_entropy(vowel_diacritic_inp, vowel_diacritic_targ) * wandb.config.vowel_diacritic_weight +\n",
    "        F.cross_entropy(consonant_diacritic_inp, consonant_diacritic_targ) * wandb.config.consonant_diacritic_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecallPartial(Metric):\n",
    "    \"\"\"Stores predictions and targets on CPU in accumulate to perform final calculations with `func`.\"\"\"\n",
    "    def __init__(self, a=0, **kwargs):\n",
    "        self.func = partial(recall_score, average='macro', zero_division=0)\n",
    "        self.a = a\n",
    "\n",
    "    def reset(self): self.targs,self.preds = [],[]\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[self.a].argmax(dim=-1)\n",
    "        targ = learn.y[self.a]\n",
    "        pred,targ = to_detach(pred),to_detach(targ)\n",
    "        pred,targ = flatten_check(pred,targ)\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(targ)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if len(self.preds) == 0: return\n",
    "        preds,targs = torch.cat(self.preds),torch.cat(self.targs)\n",
    "        return self.func(targs, preds)\n",
    "\n",
    "    @property\n",
    "    def name(self): return train_df.columns[self.a+1]\n",
    "    \n",
    "\n",
    "class RecallCombine(Metric):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.combine = 0\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        scores = [learn.metrics[i].value for i in range(3)]\n",
    "        self.combine = np.average(scores, weights=[2,1,1])\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.layers import AdaptiveConcatPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel(nn.Module):\n",
    "    def __init__(self, encoder, encoder_output_features):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=1)\n",
    "        \n",
    "        self.pooling = AdaptiveConcatPool2d(1)\n",
    "        \n",
    "        self.encoder = encoder\n",
    "    \n",
    "        self.fc_grapheme_root = MishHead(encoder_output_features, output_size=168)\n",
    "        self.fc_vowel_diacritic = MishHead(encoder_output_features, output_size=11)\n",
    "        self.fc_consonant_diacritic = MishHead(encoder_output_features, output_size=7)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        bs = inputs.size(0)\n",
    "        \n",
    "        # Convolve to 3 channels\n",
    "        x = self.input_conv(inputs)\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Pooling\n",
    "        x = self.pooling(x)\n",
    "        \n",
    "        # Final layers\n",
    "        x = x.view(bs, -1)\n",
    "\n",
    "        return [\n",
    "            self.fc_grapheme_root(x),\n",
    "            self.fc_vowel_diacritic(x),\n",
    "            self.fc_consonant_diacritic(x)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetEncoder(EfficientNet):\n",
    "    def forward(self, x):\n",
    "        \"\"\"Calls extract_features to extract features, applies final linear layer, and returns logits.\"\"\"\n",
    "        return self.extract_features(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EfficientNetEncoder.from_pretrained(ENCODER_ARCH)\n",
    "model = BengaliModel(encoder=encoder, encoder_output_features=encoder._fc.in_features)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda is available\")\n",
    "    model = model.cuda()\n",
    "    data = data.cuda()\n",
    "\n",
    "learner = Learner(\n",
    "    data,\n",
    "    model,\n",
    "    loss_func=loss_func,\n",
    "    cbs=[CSVLogger(OUTPUT_PATH/'history.csv'), WandbCallback(log_preds=False)],\n",
    "    metrics=[RecallPartial(a=i) for i in range(len(data.c))] + [RecallCombine()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first epoch, I'll train just the fc layers and the first layer, which start out as random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(12, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = learner.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
