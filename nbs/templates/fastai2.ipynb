{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.vision.all import *\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "IMAGE_DATA_PATH = Path('../data/grapheme-imgs-128x128')\n",
    "OUTPUT_PATH = Path('../data/working')\n",
    "LABELS_PATH  = Path('../data/iterative-stratification')\n",
    "\n",
    "VALID_PCT = 0.2\n",
    "SEED = 420\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 64\n",
    "\n",
    "MAX_WARP = 0.2\n",
    "P_AFFINE = 0.75\n",
    "MAX_ROTATE = 10.\n",
    "MAX_ZOOM = 1.1\n",
    "P_LIGHTING = 0.75\n",
    "MAX_LIGHTING = 0.2\n",
    "MAX_COUNT_RANDOM_ERASING = 3\n",
    "\n",
    "GRAPHEME_ROOT_WEIGHT = 2\n",
    "VOWEL_DIACRITIC_WEIGHT = 1\n",
    "CONSONANT_DIACRITIC_WEIGHT = 1\n",
    "\n",
    "SAMPLE_SIZE = None\n",
    "if torch.cuda.is_available():\n",
    "    SAMPLE_SIZE = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_kwargs = dict(size=IMG_SIZE, mode='bilinear', pad_mode=PadMode.Reflection, batch=False)\n",
    "\n",
    "AUGMENTATIONS = [\n",
    "    Warp(magnitude=MAX_WARP, p=P_AFFINE, **aug_kwargs),\n",
    "    Rotate(max_deg=MAX_ROTATE, p=P_AFFINE, **aug_kwargs),\n",
    "    Zoom(max_zoom=MAX_ZOOM, p=P_AFFINE, **aug_kwargs),\n",
    "    Brightness(max_lighting=MAX_LIGHTING, p=P_LIGHTING, batch=False),\n",
    "    Contrast(max_lighting=MAX_LIGHTING, p=P_LIGHTING, batch=False),\n",
    "    RandomErasing(max_count=MAX_COUNT_RANDOM_ERASING)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(LABELS_PATH/'train_with_fold.csv')\n",
    "if SAMPLE_SIZE:\n",
    "    train_df.sample(n=SAMPLE_SIZE, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock(cls=PILImageBW), CategoryBlock, CategoryBlock, CategoryBlock),\n",
    "    getters=[\n",
    "        ColReader('image_id', pref=IMAGE_DATA_PATH, suff='.png'),\n",
    "        ColReader('grapheme_root'),\n",
    "        ColReader('vowel_diacritic'),\n",
    "        ColReader('consonant_diacritic')\n",
    "    ],\n",
    "    splitter=IndexSplitter(train_df.loc[train_df.fold==0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = AUGMENTATIONS + [Normalize(mean=0.485, std=0.229)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AffineCoordTfm: True (TensorBBox,object) -> encodes\n",
       " (TensorPoint,object) -> encodes\n",
       " (TensorImage,object) -> encodes\n",
       " (TensorMask,object) -> encodes ,\n",
       " AffineCoordTfm: True (TensorBBox,object) -> encodes\n",
       " (TensorPoint,object) -> encodes\n",
       " (TensorImage,object) -> encodes\n",
       " (TensorMask,object) -> encodes ,\n",
       " AffineCoordTfm: True (TensorBBox,object) -> encodes\n",
       " (TensorPoint,object) -> encodes\n",
       " (TensorImage,object) -> encodes\n",
       " (TensorMask,object) -> encodes ,\n",
       " LightingTfm: True (TensorImage,object) -> encodes ,\n",
       " LightingTfm: True (TensorImage,object) -> encodes ,\n",
       " RandomErasing: False (TensorImage,object) -> encodes ,\n",
       " Normalize: True (TensorImage,object) -> encodes (TensorImage,object) -> decodes]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datablock.dataloaders(train_df, bs=BATCH_SIZE, batch_tfms=tfms)\n",
    "data.n_inp = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(inp, grapheme_root_targ, vowel_diacritic_targ, consonant_diacritic_targ):\n",
    "    grapheme_root_inp, vowel_diacritic_inp, consonant_diacritic_inp = inp\n",
    "\n",
    "    return (\n",
    "        F.cross_entropy(grapheme_root_inp, grapheme_root_targ) * GRAPHEME_ROOT_WEIGHT +\n",
    "        F.cross_entropy(vowel_diacritic_inp, vowel_diacritic_targ) * VOWEL_DIACRITIC_WEIGHT +\n",
    "        F.cross_entropy(consonant_diacritic_inp, consonant_diacritic_targ) * CONSONANT_DIACRITIC_WEIGHT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecallPartial(Metric):\n",
    "    \"\"\"Stores predictions and targets on CPU in accumulate to perform final calculations with `func`.\"\"\"\n",
    "    def __init__(self, a=0, **kwargs):\n",
    "        self.func = partial(recall_score, average='macro', zero_division=0)\n",
    "        self.a = a\n",
    "\n",
    "    def reset(self): self.targs,self.preds = [],[]\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred[self.a].argmax(dim=-1)\n",
    "        targ = learn.y[self.a]\n",
    "        pred,targ = to_detach(pred),to_detach(targ)\n",
    "        pred,targ = flatten_check(pred,targ)\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(targ)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if len(self.preds) == 0: return\n",
    "        preds,targs = torch.cat(self.preds),torch.cat(self.targs)\n",
    "        return self.func(targs, preds)\n",
    "\n",
    "    @property\n",
    "    def name(self): return train_df.columns[self.a+1]\n",
    "    \n",
    "\n",
    "class RecallCombine(Metric):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.combine = 0\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        scores = [learn.metrics[i].value for i in range(3)]\n",
    "        self.combine = np.average(scores, weights=[2,1,1])\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel(nn.Module):\n",
    "    def __init__(self, encoder, encoder_output_features):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=1)\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.encoder = encoder\n",
    "    \n",
    "        self.fc_grapheme_root = nn.Linear(in_features=encoder_output_features, out_features=168)\n",
    "        self.fc_vowel_diacritic = nn.Linear(in_features=encoder_output_features, out_features=11)\n",
    "        self.fc_consonant_diacritic = nn.Linear(in_features=encoder_output_features, out_features=7)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        bs = inputs.size(0)\n",
    "        \n",
    "        # Convolve to 3 channels\n",
    "        x = self.input_conv(inputs)\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Pooling\n",
    "        x = self.pooling(x)\n",
    "        \n",
    "        # Final layers\n",
    "        x = x.view(bs, -1)\n",
    "\n",
    "        return [\n",
    "            self.fc_grapheme_root(x),\n",
    "            self.fc_vowel_diacritic(x),\n",
    "            self.fc_consonant_diacritic(x)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetEncoder(EfficientNet):\n",
    "    def forward(self, x):\n",
    "        \"\"\"Calls extract_features to extract features, applies final linear layer, and returns logits.\"\"\"\n",
    "        return self.extract_features(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "encoder = EfficientNetEncoder.from_pretrained('efficientnet-b0')\n",
    "model = BengaliModel(encoder=encoder, encoder_output_features=encoder._fc.in_features)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    data = data.cuda()\n",
    "\n",
    "learner = Learner(\n",
    "    data,\n",
    "    model,\n",
    "    loss_func=loss_func,\n",
    "    cbs=CSVLogger(OUTPUT_PATH/'history.csv'),\n",
    "    metrics=[RecallPartial(a=i) for i in range(len(data.c))] + [RecallCombine()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first epoch, I'll train just the fc layers and the first layer, which start out as random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
